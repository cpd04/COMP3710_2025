{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c25d0729",
   "metadata": {},
   "source": [
    "# Task 4.2 - Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a2e7bf",
   "metadata": {},
   "source": [
    "Next, a UNet based magnetic resonance image segementation of the brain is used. The segmentation accuracy of the model will need to be validated and achieve > 0.9 DSC for all labels. Need to use categorical (one-hot) output in the network and must also visualise some of the segmentation results to justify the DSC (F1) scores obtrained. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f611fa6d",
   "metadata": {},
   "source": [
    "My understanding of U-net is as follows - it is a CNN used for specifically biomedical segmentation. There are two key symmetrical parts - the *encoder* and the *decoder*. What makes a U-net unique is that it includes skip connections from the encoder-decoder symmetr, uses fully convolutional design only with no dense layers, and has a U-shaped design that is fully symmetrical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f29626e",
   "metadata": {},
   "source": [
    "Our 'X' input now is the original input, and the 'segmented' images are our 'classification' in the other folder. From the segmented images we can see (with the one hot encoding) that there are 4 key categories each value can fit in:\n",
    "1. Black (presumably background)\n",
    "2. Dark Grey (potenitally 'CSF' when looking at online images)\n",
    "3. Grey (potenitally grey matter when looking at online images)\n",
    "4. Light Grey (potentially white matter when looking at online images)\n",
    "\n",
    "Therefore we need to find a way to have the UNET be able to classify each pixel into one of these four categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44330c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e3431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
